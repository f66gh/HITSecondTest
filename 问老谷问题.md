# 问老谷问题

## 项目问题

1. 目标检测技术，卷积神经网络是怎么用于目标检测的.yolo、transformer他们的优缺点，现在最前沿的目标检测技术是什么
   - yoloV8 小 商业化好 很多版本可以使用 灵活性好 已经打包了  transformer片学术，做应用不太方便，性能比yolo好，但需要自己调
   - 单阶段 目标检测技术
   - 两阶段 目标检测技术
2. 目前最前沿的目标追踪技术是什么，多目标追踪算法是最近才应用的吗
   - 多目标追踪算法 yolov8也封装好了 语义分割也封装好了
   - 目标追踪是找到连续多帧之间的同一目标
3. 语义分割是对图像中的每一个像素进行分类，确定其所属的类别，广泛应用于自动驾驶、医学影像分析、图像编辑和虚拟现实等领域。语义分割你们用的什么技术
   - yolo v8 ：segmentation图 **自己找！！**
4. 双目视觉主要用于计算深度信息，自动驾驶、机器人导航和三维重建等。用的什么算法和技术
   - 深度相机 里边包含了深度计算模块 sgbm算法 非神经网络算法
   - 神经网络算法耗时没用
   - 相机会投射激光点，不可见点阵 红外
   - 要是两个相机面对白墙就认为创造目标点，匹配两个相机keypoint
   - 两个能捕捉红外的黑白摄像机 和一个在中间的RGB摄像机：语义分割，目标检测需要用到RGB
   - 深度图和RGB对齐，可以得到RGBD信息，可以得到深度信息（距离）和彩色信息（目标检测）
5. 路径规划，A算法和**Dijkstra**。结合A*和深度学习的方法。你们用的技术
   - **问老肖 或万强**
   - 从起点开始调用一次算法 把中间要走的路都计算出来 
   - 报点的间隔 实时计算 
   - 优先把每条路起点终点都记录 建筑都记录 
   - 北斗定位 集成在 树莓派
   - 检测到偏离轨道计算 先上传起点和终点位置算完了传下来 检测是否偏航在树莓派里边 若偏航再计算一次
   - 专利的创新点在与权值
   - 为什么不用prim。因为prim是最小生成树 权值最小 但不知道起点和终点 他不是路径规划算法
     - 路径规划：dijkstra floyd A*
     - 最小生成树：克鲁思卡尔
6. 图像、语音和道路数据上传云，云计算结果下载到本地。你们这个云计算计算的是什么，是拥挤度吗？碰撞和预警系统是部署在本地的吗
   - 每人拍了四五百张照片并标注，一共2000张左右
   - 用了图像增强技术（剪裁，分割，人为增加噪声 遮挡 ），扩充到10000张
     - 计算机中的鲁棒性：一个模型面对没有见过的物体的数据迁移能力（能否正确识别）越高越好
   - 坐标转化 ： 把2D转化为3D 一个相机里边的目标有深度信息和画面里的2d坐标信息，把他转化为3d世界的真实坐标 直接GPT
7. 路线推荐算法：
   1. 道路数据库的构建和道路数据集的收集；
   2. 将道路抽象成带权无向图；
   3. 根据带权无向图的信息获取一条最优导航路线；
   4. 基于目标检测网络辅助视障人士通过红绿灯路口；
   5. 用户偏离道路后轨迹纠正，并发出提醒。本发明能综合道 路的长度、宽度、类别、人流量等信息，从而为视障人士推荐一条路况良好、距离 较近的路线，进而能保障视障人士的安全出行。
   6. **问万强**
      1. 抽象成无向图：因为能从A到B就能从B走到A。徒增工作量
8. 精准定位技术：借助移远RM500Q-GL芯片实现了PPP5G拨号上网及厘米级北斗/GPS/伽利略多星定位功能，并成功在树莓派中烧写了硬件驱动并借助busybox的microbox 实现了USB串口的AT通信成功获取定位数据，再通过远程IP访问获取实时定位 数据的功能
   - 芯片接收到5G的信号进行上下传 
   - 上传50ms+处理300ms+下载50ms：0.4s
9. 语音播报：本工作借助了 OpenAI 公司的 Wisper 开源项目成功复现了中文语音识别。要中文语音识别干啥?
   - 识别残障人士的语音
   - 调用函数 把文字转化为语音
   - 一直在说话?  
   - 功能可以开关
   - 函数输入是一段文本 输出是语音
10. 导航界面：pyqt5
11. 基于视觉理解的实时环境感知模块
    1. 计算机视觉:系统可以通过摄像头组获取前方的彩色图像，并根据两颗黑白摄像机的双目 视差计算出前方的深度图像。
    2. 双目摄像头的深度感知技术:为了获取精确的深度数据，本工作需要校正双目黑白摄像机，再通过SGBM 算法实现通过相机视差获取空间深度信息的研究
    3. 基于仿真头**HRFT**模型的声音空间定位:三维映 射模型是以使用者为原点构建的空间坐标系，坐标系中包含了每个目标的名称和 位置信息，以及视障人士位于人行道的位置，从这一模型中，**本工作可以通过语 音交互为视障人士描述周围环境中的目标名称和方位，自己位于道路两侧的距离**， 帮助视障人士了解其所处环境的信息。**你们物体识别的数据集是现成的吗** 训练好的直接用
       - 听声辨位 
    4. 目标与道路检测及碰撞预警：本工作可以通过人行道信息获取道路边缘距离使用者的距离，**再根据设备的惯性传感器（IMU）获得使用者 的速度和移动方向**，从而判断视障人士是否可能有偏离或越过人行道边缘的风险。
    5. 人行道数据集的收集与标注:。目前的道路语义分割多数是服务于自动驾驶领域，所以对应的数 据集多数为公路信息，面对校园内的多样的人行道经常出现无法识别的问题。。本工 作已经对校园内所有常见人行道路面进行数据收集集标注工作，收集了人行道特 征图像12000余张，对现有语义分割网络**进行训练**.为什么要训练？ 二分类：路 非路
12. 高性能便携式的出行导航设备模块。针对客户端与服务器的双向数据传输本工作将会使用套接字实现。

## 细节问题

1. 你们这个项目用了什么有关于深度学习和机器学习的技术
2. 深度学习和机器学习有什么区别
3. 什么是yolo，现在yolo发展到第几个版本了
4. 你们去哪里弄的测试集?自己录的吗
5. 树莓派算嵌入式的设备吗，嵌入式你们是用什么写的，树莓派的功能是什么 
   - 跑的python 负责读取数据和上传下载 播放声音
   - 运行内存8G 100M缓存
6. 你们是怎么和云端服务器的作用是什么，数据处理是在本地还是云端
7. 你这个导航系统用的什么平台
   - 高德
8. 你当时参加比赛和毕业的时候老师问你什么比较有价值的问题了吗？
   - 竞品：头上一圈做触点
   - 声音会扰乱盲人的对真实环境的感受